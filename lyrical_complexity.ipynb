{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eaae1d8-e981-46cb-b6e4-5fedc94a3656",
   "metadata": {},
   "source": [
    "1. Lexical Richness\n",
    "* Measure: Vocabulary diversity in the lyrics.\n",
    "* Metrics:\n",
    "  * Type-Token Ratio (TTR): Ratio of unique words to the total number of words.\n",
    "  * Advanced Type-Token Ratio (MTLD, HD-D): More sophisticated measures of lexical richness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1555ed1-3c57-4da4-9f17-f7bdb3ed7bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love you. You love me. We are happy together.\n",
      "Type-Token Ratio (TTR): 0.7692307692307693\n",
      "\n",
      "Text: Adoration intertwines with reciprocity, forging an eternal bond of joy.\n",
      "Type-Token Ratio (TTR): 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "simple = \"I love you. You love me. We are happy together.\"\n",
    "sophisticated = \"Adoration intertwines with reciprocity, forging an eternal bond of joy.\"\n",
    "\n",
    "for text in [simple, sophisticated]:\n",
    "    tokens = word_tokenize(text)\n",
    "    unique_tokens = set(tokens)\n",
    "    ttr = len(unique_tokens) / len(tokens)\n",
    "    print(f\"Text: {text}\\nType-Token Ratio (TTR): {ttr}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ee1f7-06bd-43ee-980d-0ee4d9180620",
   "metadata": {},
   "source": [
    "2. Readability Scores\n",
    "* Measure: How complex the lyrics are in terms of readability.\n",
    "* Metrics:\n",
    "  * Flesch Reading Ease Score: Higher scores mean simpler text.\n",
    "  * Gunning Fog Index: Estimates years of education needed to understand the text.\n",
    "  * Dale-Chall Index: Considers the proportion of difficult words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbd2c6e-6fd4-4c93-b2e0-ee6e11c4c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The cat sat on the mat. The sun is shining.\n",
      "Flesch Reading Ease: 108.7\n",
      "Gunning Fog Index: 2.0\n",
      "Dale-Chall Score: 0.25 \n",
      "\n",
      "Text: The feline gracefully reclined upon the ornate rug while the celestial sphere radiated brilliance.\n",
      "Flesch Reading Ease: 31.89\n",
      "Gunning Fog Index: 14.17\n",
      "Dale-Chall Score: 13.35 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textstat import flesch_reading_ease, gunning_fog, dale_chall_readability_score\n",
    "\n",
    "simple = \"The cat sat on the mat. The sun is shining.\"\n",
    "sophisticated = \"The feline gracefully reclined upon the ornate rug while the celestial sphere radiated brilliance.\"\n",
    "\n",
    "for text in [simple, sophisticated]:\n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"Flesch Reading Ease:\", flesch_reading_ease(text))\n",
    "    print(\"Gunning Fog Index:\", gunning_fog(text))\n",
    "    print(\"Dale-Chall Score:\", dale_chall_readability_score(text), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e753adf-60bd-4d79-990e-d63b55e7513f",
   "metadata": {},
   "source": [
    "3. Semantic Depth\n",
    "* Measure: Depth of meaning and abstractness.\n",
    "* Metrics:\n",
    "  * WordNet Synset Depth: Use WordNet (via nltk) to calculate the average depth of words in a lexical taxonomy.\n",
    "  * Sentiment Complexity: Use tools like VADER or TextBlob to detect nuanced sentiment variation within the lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "364a9def-4736-48f1-bedd-4b3f2dd7579d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Love is kind and good.\n",
      "Average Semantic Depth: 8.75\n",
      "\n",
      "Text: Altruism embodies kindness and magnanimity, transcending mundane affection.\n",
      "Average Semantic Depth: 6.571428571428571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "simple = \"Love is kind and good.\"\n",
    "sophisticated = \"Altruism embodies kindness and magnanimity, transcending mundane affection.\"\n",
    "\n",
    "for text in [simple, sophisticated]:\n",
    "    tokens = word_tokenize(text)\n",
    "    synset_depths = [max(len(ss.hypernym_paths()[0]) for ss in wn.synsets(word)) \n",
    "                     for word in tokens if wn.synsets(word)]\n",
    "    avg_depth = sum(synset_depths) / len(synset_depths) if synset_depths else 0\n",
    "    print(f\"Text: {text}\\nAverage Semantic Depth: {avg_depth}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ffb1c-0fd9-4115-83c0-72ad8b425a56",
   "metadata": {},
   "source": [
    "4. Syntactic Complexity\n",
    "* Measure: Sentence structure and grammatical sophistication.\n",
    "* Metrics:\n",
    "  * Average Sentence Length: Number of words per sentence.\n",
    "  * Parse Tree Depth: Using NLP parsers like spaCy to calculate the depth of syntactic trees.\n",
    "  * Clause-to-Sentence Ratio: Ratio of clauses to sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3296292-c183-423f-b6c5-ebd973018804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The dog runs fast.\n",
      "Average Sentence Length: 4.0\n",
      "\n",
      "Text: Bounding swiftly across the verdant meadow, the canine displayed unparalleled agility.\n",
      "Average Sentence Length: 11.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "simple = \"The dog runs fast.\"\n",
    "sophisticated = \"Bounding swiftly across the verdant meadow, the canine displayed unparalleled agility.\"\n",
    "\n",
    "for text in [simple, sophisticated]:\n",
    "    doc = nlp(text)\n",
    "    sent_lengths = [len(sent.text.split()) for sent in doc.sents]\n",
    "    avg_length = sum(sent_lengths) / len(sent_lengths)\n",
    "    print(f\"Text: {text}\\nAverage Sentence Length: {avg_length}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5619ba-e25d-4c17-97fd-df191667ecb0",
   "metadata": {},
   "source": [
    "5. Rhyme Density and Patterning\n",
    "* Measure: Intricacy of rhyming schemes and patterns.\n",
    "* Metrics:\n",
    "  * Rhyme Density: Ratio of rhyming words to total words.\n",
    "  * Rhyme Complexity: Use phonetic matching (e.g., pronouncing library) to analyze internal rhymes or multisyllabic rhymes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483a5dfe-71ff-4549-aca2-3fb8708bb7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The cat sat on the mat.\n",
      "Rhyme Density: 0.3333333333333333\n",
      "\n",
      "Text: Though the twilight fades, serenades of cascading shades pervade.\n",
      "Rhyme Density: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pronouncing\n",
    "\n",
    "simple = \"The cat sat on the mat.\"\n",
    "sophisticated = \"Though the twilight fades, serenades of cascading shades pervade.\"\n",
    "\n",
    "for text in [simple, sophisticated]:\n",
    "    lines = text.split(\".\")\n",
    "    rhyme_pairs = 0\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "        if len(words) > 1 and pronouncing.rhymes(words[-1]):\n",
    "            rhymes = [w for w in pronouncing.rhymes(words[-1]) if w in words]\n",
    "            rhyme_pairs += len(rhymes)\n",
    "    rhyme_density = rhyme_pairs / len(text.split())\n",
    "    print(f\"Text: {text}\\nRhyme Density: {rhyme_density}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03359b4-71a9-4fb3-a2d3-7b3b7f38e37c",
   "metadata": {},
   "source": [
    "6. Sentiment Variability\n",
    "* Measure: Range of emotions expressed in the lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307b19d5-9c82-4769-9050-d465aaa03306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I am happy. I feel good.\n",
      "Sentiment Variability: 0.09298454172603096\n",
      "\n",
      "Text: Though elation surged like a tidal wave, an undertow of melancholic introspection lingered.\n",
      "Sentiment Variability: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import statistics\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "simple = \"I am happy. I feel good.\"\n",
    "sophisticated = \"Though elation surged like a tidal wave, an undertow of melancholic introspection lingered.\"\n",
    "\n",
    "for text in [simple, sophisticated]:\n",
    "    lines = text.split(\". \")\n",
    "    scores = [analyzer.polarity_scores(line)['compound'] for line in lines]\n",
    "    variability = statistics.stdev(scores) if len(scores) > 1 else 0\n",
    "    print(f\"Text: {text}\\nSentiment Variability: {variability}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71566d61-d219-4739-8560-168bac725dcb",
   "metadata": {},
   "source": [
    "7. Linguistic Uniqueness\n",
    "* Measure: Rarity of the vocabulary used.\n",
    "Implementation:\n",
    "* Compare the words in the lyrics against a frequency list (e.g., Google Books Ngram corpus).\n",
    "* Calculate the percentage of rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007315a0-27c4-4d38-920d-1126422727ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The cat sat on the mat.\n",
      "Linguistic Uniqueness Ratio: 0.00\n",
      "\n",
      "Text: Ephemeral whispers danced through the corridors of oblivion.\n",
      "Linguistic Uniqueness Ratio: 0.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from wordfreq import word_frequency\n",
    "\n",
    "simple = \"The cat sat on the mat.\"\n",
    "sophisticated = \"Ephemeral whispers danced through the corridors of oblivion.\"\n",
    "\n",
    "def uniqueness_ratio(lyrics):\n",
    "    tokens = lyrics.lower().split()\n",
    "    clean_tokens = [word.strip(\",.\") for word in tokens]\n",
    "    \n",
    "    # Use a threshold to determine \"rare\" words\n",
    "    threshold = 1e-6  # Frequency below this is rare\n",
    "    rare_words = [word for word in clean_tokens if word_frequency(word, 'en') < threshold]\n",
    "    ratio = len(rare_words) / len(clean_tokens)\n",
    "    return ratio\n",
    "\n",
    "for text in [simple, sophisticated]:\n",
    "    print(f\"Text: {text}\\nLinguistic Uniqueness Ratio: {uniqueness_ratio(text):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723aba47-4aa7-464b-9ba7-d2068d6eaed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
